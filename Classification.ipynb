{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import spacy\n",
    "from wordfreq import zipf_frequency\n",
    "import seaborn as sns\n",
    "import os.path\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"en_core_web_lg\"\n",
    "nlp = spacy.load(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from parse_data import TextsinlevelsDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "textsinlevels = TextsinlevelsDB(db_name=\"textsinlevels\")\n",
    "df_news = textsinlevels.write_from_table_to_df(\"newsinlevels\")\n",
    "df_days = textsinlevels.write_from_table_to_df(\"daysinlevels\")\n",
    "del textsinlevels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "LEVELS = (\"A1\", \"A2\", \"B1\", \"B2\", \"C1\", \"C2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Text:\n",
    "    def __init__(self, tokens):\n",
    "        self.tokens = tokens\n",
    "        self.lemmas = self.lemmatize()\n",
    "    \n",
    "    def lemmatize(self):\n",
    "        return [token.lemma_.lower() for token in self.tokens\n",
    "                       if token.is_alpha]\n",
    "    \n",
    "    def count_words(self):\n",
    "        n_words = 0\n",
    "        for token in self.tokens:\n",
    "            if token.is_alpha:\n",
    "                n_words += 1\n",
    "        return n_words\n",
    "    \n",
    "    def count_sentences(self):\n",
    "        n_sentences = 0\n",
    "        for sent in self.tokens.sents:\n",
    "            n_sentences += 1\n",
    "        return n_sentences\n",
    "    \n",
    "    def count_type_token_ratio(self):\n",
    "        return len(set(self.lemmas)) / len(self.lemmas) \n",
    "    \n",
    "    def count_words_from_wordlist(self, wordlist):\n",
    "        words_from_wordlists = 0\n",
    "        \n",
    "        for lemma in self.lemmas:\n",
    "            if lemma in wordlist:\n",
    "                words_from_wordlists += 1\n",
    "        \n",
    "        return words_from_wordlists / len(self.lemmas)\n",
    "    \n",
    "    def count_words_from_level_lists(self, word2level):\n",
    "        level_freqs = {level: 0 for level in LEVELS}\n",
    "        \n",
    "        for lemma in self.lemmas:\n",
    "            level = word2level.get(lemma)\n",
    "            if level:\n",
    "                level_freqs[level] += 1\n",
    "\n",
    "        for level in level_freqs:\n",
    "            level_freqs[level] /= len(self.lemmas)\n",
    "            \n",
    "        return level_freqs\n",
    "    \n",
    "    def count_zipf_freqs(self):\n",
    "        zipf_freqs = {}\n",
    "        \n",
    "        for lemma in self.lemmas:\n",
    "            zipf_freq = math.floor(zipf_frequency(lemma, \"en\"))\n",
    "            if zipf_freq in zipf_freqs:\n",
    "                zipf_freqs[zipf_freq] += 1\n",
    "            else:\n",
    "                zipf_freqs[zipf_freq] = 1\n",
    "        \n",
    "        for zipf_freq in zipf_freqs:\n",
    "            zipf_freqs[zipf_freq] /= len(self.lemmas)\n",
    "        \n",
    "        return zipf_freqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextDataset:\n",
    "    def __init__(self, dataset, dataset_name, nlp, preprocess):\n",
    "        self.dataset_name = dataset_name\n",
    "        self.dataset = dataset\n",
    "        if preprocess:\n",
    "            docs = spacy.tokens.DocBin(store_user_data=False)\n",
    "            for doc in nlp.pipe(tqdm(self.dataset[\"article_text\"])):\n",
    "                docs.add(doc)\n",
    "            docs.to_disk(self.dataset_name)\n",
    "        else:\n",
    "            docs = spacy.tokens.DocBin().from_disk(self.dataset_name)\n",
    "        self.texts = [Text(doc) for doc in docs.get_docs(spacy.blank(\"en\").vocab)]\n",
    "    \n",
    "    def count_words(self):\n",
    "        return [text.count_words() for text in self.texts]\n",
    "    \n",
    "    def count_sentences(self):\n",
    "        return [text.count_sentences() for text in self.texts]\n",
    "    \n",
    "    def lemmatize(self):\n",
    "        return [text.lemmatize() for text in self.texts]\n",
    "    \n",
    "    def count_type_token_ratio(self):\n",
    "        return [text.count_type_token_ratio() for text in self.texts]\n",
    "    \n",
    "    def count_words_from_wordlist(self, wordlist):\n",
    "        return [text.count_words_from_wordlist(wordlist) for text in self.texts]\n",
    "    \n",
    "    def count_words_from_level_lists(self, word2level):\n",
    "        return [text.count_words_from_level_lists(word2level) for text in self.texts]\n",
    "        \n",
    "    def count_zipf_freqs(self):\n",
    "        return [text.count_zipf_freqs() for text in self.texts]\n",
    "                \n",
    "    def show_counts_info(self):\n",
    "        print(self.dataset_name)\n",
    "        d = {\"Number of words\": self.count_words(),\n",
    "            \"Number of sentences\": self.count_sentences()}\n",
    "        df_stats = pd.DataFrame(d)\n",
    "        print(df_stats.describe())\n",
    "\n",
    "        f = plt.figure(figsize=(10, 4))\n",
    "        plt.suptitle(self.dataset_name)\n",
    "        gs = f.add_gridspec(1, 2)\n",
    "\n",
    "        for i, col in enumerate(d):\n",
    "            ax = f.add_subplot(gs[0, i])\n",
    "            ax = sns.distplot(df_stats[col], bins=20)\n",
    "\n",
    "        plt.show()\n",
    "        f.savefig(f\"{self.dataset_name}-words_sentences_counts.png\")\n",
    "    \n",
    "    def create_lexical_df(self, abstract_nouns, concrete_nouns):\n",
    "        dct_lexical = {\"words\": [\" \".join(self.texts[i].lemmas) for i in range(len(self.texts))],\n",
    "                       \"word_count\": self.count_words(),\n",
    "                       \"type_token_ratio\": self.count_type_token_ratio(),\n",
    "                       \"abstract_nouns\": self.count_words_from_wordlist(abstract_nouns),\n",
    "                       \"concrete_nouns\": self.count_words_from_wordlist(concrete_nouns),\n",
    "                       \"level\": self.dataset[\"level\"]}\n",
    "                       \n",
    "        zipf_freqs = self.count_zipf_freqs()\n",
    "        \n",
    "        for i in range(1, 7):\n",
    "            dct_lexical[f\"zipf_freqs_{i}\"] = [dct.get(i, 0) for dct in zipf_freqs]\n",
    "        \n",
    "        for level in LEVELS:\n",
    "            dct_lexical[level] = [dct[level] for dct in self.count_words_from_level_lists(word2level)]\n",
    "        \n",
    "        df_lexical = pd.DataFrame(dct_lexical)\n",
    "        return df_lexical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_word_list(filename):\n",
    "    with open(f\"wordlists/{filename}\", encoding='utf-8') as f:\n",
    "        words_from_list = f.read().split('\\n')\n",
    "        \n",
    "    words_from_list = ' '.join([w for w in words_from_list if \" \" not in w and \"-\" not in w])\n",
    "    words_from_list = nlp(words_from_list)\n",
    "    words_from_list = set(w.lemma_.lower() for w in words_from_list)\n",
    "    return words_from_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160 384\n"
     ]
    }
   ],
   "source": [
    "abstract_nouns = preprocess_word_list(\"abstract_nouns.txt\")\n",
    "concrete_nouns = preprocess_word_list(\"concrete_nouns.txt\")\n",
    "print(len(abstract_nouns), len(concrete_nouns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_word2level_dct():\n",
    "    dct = {}\n",
    "    df = pd.read_csv(\"wordlists/Vocabulary Framework – British English.csv\")\n",
    "    sub_df = df[[\"Base Word\", \"Level\"]]\n",
    "    sub_df_min = sub_df.groupby(\"Base Word\").min()\n",
    "    for d, data in sub_df_min.reset_index().groupby(\"Level\"):\n",
    "        dct[d] = list(data[\"Base Word\"])\n",
    "    \n",
    "    word2level = {}\n",
    "    for level, words in dct.items():\n",
    "        for i in range(len(words)):\n",
    "            if ' ' not in words[i]:\n",
    "                word2level[words[i].lower()] = level\n",
    "    \n",
    "    return word2level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2level = create_word2level_dct()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "news = TextDataset(dataset=df_news, dataset_name=\"news\", nlp=nlp, preprocess=False)\n",
    "days = TextDataset(dataset=df_days, dataset_name=\"days\", nlp=nlp, preprocess=False)\n",
    "\n",
    "news_lexical_df = news.create_lexical_df(abstract_nouns, concrete_nouns)\n",
    "days_lexical_df = days.create_lexical_df(abstract_nouns, concrete_nouns)\n",
    "\n",
    "news_lexical_df['level'] = news_lexical_df['level'].map({1:0, 2:1, 3:2}) \n",
    "Y = news_lexical_df[\"level\"]\n",
    "X = news_lexical_df.drop(columns=[\"level\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import mord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyTfidfVectorizer(TfidfVectorizer):\n",
    "        \n",
    "    def fit_transform(self, raw_documents, y):\n",
    "        X = TfidfVectorizer.fit_transform(self, raw_documents, y=None)\n",
    "        return X/X.sum(axis=1)\n",
    "\n",
    "    def transform(self, raw_documents):\n",
    "        X = TfidfVectorizer.transform(self, raw_documents)\n",
    "        return X/X.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_coefs(estimator, n_top_features, filename):\n",
    "     \n",
    "    coef = estimator[-1].coef_\n",
    "    n_classes = coef.shape[0]\n",
    "    feature_names = np.array(estimator.named_steps['vectorizer'].get_feature_names())\n",
    "    print(len(feature_names))\n",
    "    \n",
    "\n",
    "    for n in range(n_classes):\n",
    "        print('class', n)\n",
    "        coefs = np.argsort(coef[n])\n",
    "        \n",
    "        if len(feature_names) > 2 * n_top_features:\n",
    "            # индексы признаков, получивших cамые большие положительные коэффициенты\n",
    "            pos_coefs = coefs[-n_top_features:]\n",
    "\n",
    "            # индексы признаков, получивших самые низкие отрицательные коэффициенты\n",
    "            neg_coefs = coefs[:n_top_features]\n",
    "\n",
    "            interesting_coefs = np.hstack([neg_coefs, pos_coefs])\n",
    "\n",
    "            plt.figure(figsize=(9, 3))\n",
    "            colors = [\"red\" if c < 0 else \"green\" for c in coef[n][interesting_coefs]]\n",
    "            plt.bar(np.arange(2 * n_top_features), coef[n][interesting_coefs], color=colors)\n",
    "            plt.xticks(np.arange(2 * n_top_features), feature_names[interesting_coefs], rotation=90, ha=\"right\")\n",
    "        else:\n",
    "            colors = [\"red\" if c < 0 else \"green\" for c in coef[n][coefs]]\n",
    "            plt.bar(np.arange(len(feature_names)), coef[n][coefs], color=colors)\n",
    "            plt.xticks(np.arange(len(feature_names)), feature_names[coefs], rotation=90, ha=\"right\")\n",
    "        \n",
    "        directory = \"illustrations\"\n",
    "        if not os.path.exists(\"illustrations\"):\n",
    "            os.makedirs(directory)\n",
    "            \n",
    "        plt.savefig(os.path.join(directory, f\"{filename}_class{n}.png\"), bbox_inches='tight')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_feature_importances(estimator, n_top_features, filename):\n",
    "    coef = estimator[-1].feature_importances_\n",
    "    feature_names = np.array(estimator.named_steps['vectorizer'].get_feature_names())\n",
    "    word_importances = pd.Series(coef, index=feature_names).sort_values(ascending=False)[:10]\n",
    "    word_importances.plot(kind='bar')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(\"illustrations\", filename), bbox_inches='tight')\n",
    "    plt.show()\n",
    "    return feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PassthroughTransformer(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        self.X = X\n",
    "        return X\n",
    "\n",
    "    def get_feature_names(self):\n",
    "        return self.X.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quality(y_actual, y_pred):\n",
    "    acc = accuracy_score(y_actual, y_pred)\n",
    "    f1 = f1_score(y_actual, y_pred, average=\"macro\")\n",
    "    print(f\"Accuracy: {acc:.4f}\\nF1 macro: {f1:.4f}\")\n",
    "    \n",
    "    cm = confusion_matrix(y_actual, y_pred)\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", annot_kws={\"size\": 16})\n",
    "    plt.ylabel(\"True\")\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.show()\n",
    "\n",
    "    return acc, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MaxAbsScaler()\n",
    "vectorizer = MyTfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(solver=\"liblinear\")\n",
    "svm = LinearSVC()\n",
    "tree = DecisionTreeClassifier()\n",
    "adaboost = AdaBoostClassifier()\n",
    "random_forest = RandomForestClassifier()\n",
    "extra_trees = ExtraTreesClassifier()\n",
    "lgbm = LGBMClassifier()\n",
    "logistic_at = mord.LogisticAT()\n",
    "logistic_it = mord.LogisticIT()\n",
    "logistic_se = mord.LogisticSE()\n",
    "ordinal_ridge = mord.OrdinalRidge()\n",
    "lad = mord.LAD()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_params = dict(vectorizer__word__min_df=[3, 5, 7], lr__C=[0.1, 0.5, 1], lr__penalty=[\"l1\", \"l2\"])\n",
    "svm_params = dict(vectorizer__word__min_df=[3, 5, 7], svm__C=[0.01, 0.1, 1])\n",
    "tree_params = dict(vectorizer__word__min_df=[3, 5, 7], tree__max_depth=[None, 7, 10],\n",
    "                tree__min_samples_leaf=[1, 10])\n",
    "adaboost_params = dict(vectorizer__word__min_df=[3, 5, 7], adaboost__base_estimator=[DecisionTreeClassifier(max_depth=1),\n",
    "                        DecisionTreeClassifier(max_depth=2)])\n",
    "random_forest_params = dict(vectorizer__word__min_df=[3, 5, 7], random_forest__max_depth=[None, 10],\n",
    "                       random_forest__min_samples_leaf=[1, 5])\n",
    "extra_trees_params = dict(vectorizer__word__min_df=[3, 5, 7], extra_trees__max_depth=[None, 15],\n",
    "                       extra_trees__min_samples_leaf=[1, 15])\n",
    "lgbm_params = dict(vectorizer__word__min_df=[3, 5, 7], lgbm__min_split_gain=[0, 0.5], lgbm__colsample_bytree=[0.25, 0.5, 1])\n",
    "logistic_at_params = dict(vectorizer__word__min_df=[3, 5, 7], logistic_at__alpha=[0.5, 1, 5])\n",
    "logistic_it_params = dict(vectorizer__word__min_df=[3, 5, 7], logistic_it__alpha=[0.5, 1, 5])\n",
    "logistic_se_params = dict(vectorizer__word__min_df=[3, 5, 7], logistic_se__alpha=[0.5, 1, 5])\n",
    "ordinal_ridge_params = dict(vectorizer__word__min_df=[3, 5, 7], ordinal_ridge__alpha=[0.5, 1, 5])\n",
    "lad_params = dict(vectorizer__word__min_df=[3, 5, 7], lad__C=[0.01, 0.1, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "clfs = {\n",
    "    \"lr\": [lr, lr_params],\n",
    "    \"svm\": [svm, svm_params],\n",
    "    \"tree\": [tree, tree_params],\n",
    "    \"adaboost\": [adaboost, adaboost_params],\n",
    "    \"random_forest\": [random_forest, random_forest_params],\n",
    "    \"extra_trees\": [extra_trees, extra_trees_params],\n",
    "    \"lgbm\": [lgbm, lgbm_params],\n",
    "    \"lad\": [lad, lad_params],\n",
    "    \"ordinal_ridge\": [ordinal_ridge, ordinal_ridge_params],\n",
    "    \"logistic_se\": [logistic_se, logistic_se_params],\n",
    "    \"logistic_at\": [logistic_at, logistic_at_params],\n",
    "    \"logistic_it\": [logistic_it, logistic_it_params],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_based = {\"tree\", \"adaboost\", \"random_forest\", \"extra_trees\", \"lgbm\"}\n",
    "with_coefs = {\"lr\", \"svm\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_trans = ColumnTransformer(\n",
    "            [('word', vectorizer, \"words\"), \n",
    "            ('feature', PassthroughTransformer(), [*lexical_features])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "lexical_features = ['zipf_freqs_1', 'zipf_freqs_2', 'zipf_freqs_3', 'zipf_freqs_4',\n",
    "       'zipf_freqs_5', 'zipf_freqs_6', 'A1', 'A2', 'B1', 'B2', 'C1', 'C2',\n",
    "       'type_token_ratio', 'abstract_nouns', 'concrete_nouns']\n",
    "\n",
    "grammatical_features = []\n",
    "\n",
    "all_features = lexical_features + grammatical_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = {\"lexical\": lexical_features,\n",
    "            \"grammatical\": grammatical_features,\n",
    "            \"all\": all_features}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "\n",
    "for feature_set in features:\n",
    "    results[feature_set] = {\"F1 macro (validation)\": {},\n",
    "                        \"Best params\": {},\n",
    "                        \"Accuracy (test)\": {},\n",
    "                        \"F1 macro (test)\": {}\n",
    "                       }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits=4, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, \n",
    "                                                    train_size=0.8, \n",
    "                                                    random_state=42,\n",
    "                                                   stratify=Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 12 candidates, totalling 48 fits\n",
      "[CV 1/4; 1/12] START lad__C=0.01, vectorizer__word__min_df=3....................\n",
      "[CV 1/4; 1/12] END lad__C=0.01, vectorizer__word__min_df=3; Accuracy: (train=0.858, test=0.811) F1: (train=0.862, test=0.815) total time=   2.4s\n",
      "[CV 2/4; 1/12] START lad__C=0.01, vectorizer__word__min_df=3....................\n",
      "[CV 2/4; 1/12] END lad__C=0.01, vectorizer__word__min_df=3; Accuracy: (train=0.858, test=0.808) F1: (train=0.861, test=0.814) total time=   2.3s\n",
      "[CV 3/4; 1/12] START lad__C=0.01, vectorizer__word__min_df=3....................\n",
      "[CV 3/4; 1/12] END lad__C=0.01, vectorizer__word__min_df=3; Accuracy: (train=0.854, test=0.822) F1: (train=0.857, test=0.826) total time=   2.3s\n",
      "[CV 4/4; 1/12] START lad__C=0.01, vectorizer__word__min_df=3....................\n",
      "[CV 4/4; 1/12] END lad__C=0.01, vectorizer__word__min_df=3; Accuracy: (train=0.855, test=0.836) F1: (train=0.859, test=0.840) total time=   2.3s\n",
      "[CV 1/4; 2/12] START lad__C=0.01, vectorizer__word__min_df=5....................\n",
      "[CV 1/4; 2/12] END lad__C=0.01, vectorizer__word__min_df=5; Accuracy: (train=0.857, test=0.813) F1: (train=0.860, test=0.818) total time=   1.8s\n",
      "[CV 2/4; 2/12] START lad__C=0.01, vectorizer__word__min_df=5....................\n",
      "[CV 2/4; 2/12] END lad__C=0.01, vectorizer__word__min_df=5; Accuracy: (train=0.857, test=0.810) F1: (train=0.860, test=0.815) total time=   1.9s\n",
      "[CV 3/4; 2/12] START lad__C=0.01, vectorizer__word__min_df=5....................\n",
      "[CV 3/4; 2/12] END lad__C=0.01, vectorizer__word__min_df=5; Accuracy: (train=0.851, test=0.822) F1: (train=0.854, test=0.826) total time=   1.8s\n",
      "[CV 4/4; 2/12] START lad__C=0.01, vectorizer__word__min_df=5....................\n",
      "[CV 4/4; 2/12] END lad__C=0.01, vectorizer__word__min_df=5; Accuracy: (train=0.850, test=0.840) F1: (train=0.854, test=0.843) total time=   1.9s\n",
      "[CV 1/4; 3/12] START lad__C=0.01, vectorizer__word__min_df=7....................\n",
      "[CV 1/4; 3/12] END lad__C=0.01, vectorizer__word__min_df=7; Accuracy: (train=0.854, test=0.812) F1: (train=0.857, test=0.817) total time=   1.6s\n",
      "[CV 2/4; 3/12] START lad__C=0.01, vectorizer__word__min_df=7....................\n",
      "[CV 2/4; 3/12] END lad__C=0.01, vectorizer__word__min_df=7; Accuracy: (train=0.854, test=0.811) F1: (train=0.858, test=0.816) total time=   1.7s\n",
      "[CV 3/4; 3/12] START lad__C=0.01, vectorizer__word__min_df=7....................\n",
      "[CV 3/4; 3/12] END lad__C=0.01, vectorizer__word__min_df=7; Accuracy: (train=0.852, test=0.825) F1: (train=0.855, test=0.829) total time=   1.6s\n",
      "[CV 4/4; 3/12] START lad__C=0.01, vectorizer__word__min_df=7....................\n",
      "[CV 4/4; 3/12] END lad__C=0.01, vectorizer__word__min_df=7; Accuracy: (train=0.849, test=0.837) F1: (train=0.853, test=0.841) total time=   1.6s\n",
      "[CV 1/4; 4/12] START lad__C=0.1, vectorizer__word__min_df=3.....................\n",
      "[CV 1/4; 4/12] END lad__C=0.1, vectorizer__word__min_df=3; Accuracy: (train=0.951, test=0.828) F1: (train=0.952, test=0.832) total time=   2.4s\n",
      "[CV 2/4; 4/12] START lad__C=0.1, vectorizer__word__min_df=3.....................\n",
      "[CV 2/4; 4/12] END lad__C=0.1, vectorizer__word__min_df=3; Accuracy: (train=0.948, test=0.815) F1: (train=0.949, test=0.819) total time=   2.5s\n",
      "[CV 3/4; 4/12] START lad__C=0.1, vectorizer__word__min_df=3.....................\n",
      "[CV 3/4; 4/12] END lad__C=0.1, vectorizer__word__min_df=3; Accuracy: (train=0.946, test=0.830) F1: (train=0.947, test=0.833) total time=   2.4s\n",
      "[CV 4/4; 4/12] START lad__C=0.1, vectorizer__word__min_df=3.....................\n",
      "[CV 4/4; 4/12] END lad__C=0.1, vectorizer__word__min_df=3; Accuracy: (train=0.950, test=0.838) F1: (train=0.950, test=0.841) total time=   2.4s\n",
      "[CV 1/4; 5/12] START lad__C=0.1, vectorizer__word__min_df=5.....................\n",
      "[CV 1/4; 5/12] END lad__C=0.1, vectorizer__word__min_df=5; Accuracy: (train=0.939, test=0.825) F1: (train=0.939, test=0.829) total time=   2.0s\n",
      "[CV 2/4; 5/12] START lad__C=0.1, vectorizer__word__min_df=5.....................\n",
      "[CV 2/4; 5/12] END lad__C=0.1, vectorizer__word__min_df=5; Accuracy: (train=0.936, test=0.817) F1: (train=0.937, test=0.820) total time=   2.0s\n",
      "[CV 3/4; 5/12] START lad__C=0.1, vectorizer__word__min_df=5.....................\n",
      "[CV 3/4; 5/12] END lad__C=0.1, vectorizer__word__min_df=5; Accuracy: (train=0.937, test=0.827) F1: (train=0.937, test=0.831) total time=   2.0s\n",
      "[CV 4/4; 5/12] START lad__C=0.1, vectorizer__word__min_df=5.....................\n",
      "[CV 4/4; 5/12] END lad__C=0.1, vectorizer__word__min_df=5; Accuracy: (train=0.936, test=0.836) F1: (train=0.937, test=0.839) total time=   2.0s\n",
      "[CV 1/4; 6/12] START lad__C=0.1, vectorizer__word__min_df=7.....................\n",
      "[CV 1/4; 6/12] END lad__C=0.1, vectorizer__word__min_df=7; Accuracy: (train=0.931, test=0.827) F1: (train=0.932, test=0.831) total time=   1.7s\n",
      "[CV 2/4; 6/12] START lad__C=0.1, vectorizer__word__min_df=7.....................\n",
      "[CV 2/4; 6/12] END lad__C=0.1, vectorizer__word__min_df=7; Accuracy: (train=0.928, test=0.822) F1: (train=0.929, test=0.826) total time=   1.7s\n",
      "[CV 3/4; 6/12] START lad__C=0.1, vectorizer__word__min_df=7.....................\n",
      "[CV 3/4; 6/12] END lad__C=0.1, vectorizer__word__min_df=7; Accuracy: (train=0.925, test=0.839) F1: (train=0.925, test=0.842) total time=   1.7s\n",
      "[CV 4/4; 6/12] START lad__C=0.1, vectorizer__word__min_df=7.....................\n",
      "[CV 4/4; 6/12] END lad__C=0.1, vectorizer__word__min_df=7; Accuracy: (train=0.927, test=0.839) F1: (train=0.928, test=0.842) total time=   1.8s\n",
      "[CV 1/4; 7/12] START lad__C=0.5, vectorizer__word__min_df=3.....................\n",
      "[CV 1/4; 7/12] END lad__C=0.5, vectorizer__word__min_df=3; Accuracy: (train=0.976, test=0.770) F1: (train=0.976, test=0.774) total time=   3.1s\n",
      "[CV 2/4; 7/12] START lad__C=0.5, vectorizer__word__min_df=3.....................\n",
      "[CV 2/4; 7/12] END lad__C=0.5, vectorizer__word__min_df=3; Accuracy: (train=0.977, test=0.760) F1: (train=0.977, test=0.764) total time=   3.0s\n",
      "[CV 3/4; 7/12] START lad__C=0.5, vectorizer__word__min_df=3.....................\n",
      "[CV 3/4; 7/12] END lad__C=0.5, vectorizer__word__min_df=3; Accuracy: (train=0.969, test=0.769) F1: (train=0.970, test=0.772) total time=   3.0s\n",
      "[CV 4/4; 7/12] START lad__C=0.5, vectorizer__word__min_df=3.....................\n",
      "[CV 4/4; 7/12] END lad__C=0.5, vectorizer__word__min_df=3; Accuracy: (train=0.973, test=0.773) F1: (train=0.973, test=0.777) total time=   3.0s\n",
      "[CV 1/4; 8/12] START lad__C=0.5, vectorizer__word__min_df=5.....................\n",
      "[CV 1/4; 8/12] END lad__C=0.5, vectorizer__word__min_df=5; Accuracy: (train=0.960, test=0.770) F1: (train=0.960, test=0.775) total time=   2.7s\n",
      "[CV 2/4; 8/12] START lad__C=0.5, vectorizer__word__min_df=5.....................\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m             Traceback (most recent call last)",
      "\u001b[1;32mc:\\users\\family\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\u001b[0m in \u001b[0;36m_cached_call\u001b[1;34m(cache, estimator, method, *args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 71\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mcache\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     72\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'predict'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m    Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-235-bde0ed542381>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m                            \u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m\"F1\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m\"f1_macro\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Accuracy\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m\"accuracy\"\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m                            refit=\"F1\", return_train_score=True, cv=skf, verbose=10) \n\u001b[1;32m---> 10\u001b[1;33m     \u001b[0mgrid_search\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m     \u001b[0mbest_f1_val\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mround\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrid_search\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_score_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0mbest_params\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgrid_search\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\family\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    889\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    890\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 891\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    892\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    893\u001b[0m             \u001b[1;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\family\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1390\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1391\u001b[0m         \u001b[1;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1392\u001b[1;33m         \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1393\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1394\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\family\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    849\u001b[0m                     )\n\u001b[0;32m    850\u001b[0m                     for (cand_idx, parameters), (split_idx, (train, test)) in product(\n\u001b[1;32m--> 851\u001b[1;33m                         \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcandidate_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    852\u001b[0m                     )\n\u001b[0;32m    853\u001b[0m                 )\n",
      "\u001b[1;32mc:\\users\\family\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    922\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    923\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 924\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    925\u001b[0m                 \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    926\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\family\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    757\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    758\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 759\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    760\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    761\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\family\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    714\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    715\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 716\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    717\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    718\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\family\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    180\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    181\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 182\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    183\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\family\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    547\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    548\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 549\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    550\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    551\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\family\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    223\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 225\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    226\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\family\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    223\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 225\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    226\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\family\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\utils\\fixes.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    214\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    215\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 216\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    217\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    218\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\family\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[0;32m    703\u001b[0m         \u001b[0mscore_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mstart_time\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mfit_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    704\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mreturn_train_score\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 705\u001b[1;33m             \u001b[0mtrain_scores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscorer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merror_score\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    706\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    707\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mverbose\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\family\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_score\u001b[1;34m(estimator, X_test, y_test, scorer, error_score)\u001b[0m\n\u001b[0;32m    759\u001b[0m             \u001b[0mscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscorer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    760\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 761\u001b[1;33m             \u001b[0mscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscorer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    762\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    763\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0merror_score\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"raise\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\family\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m    101\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscorer\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_scorers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscorer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_BaseScorer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 103\u001b[1;33m                 \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscorer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcached_call\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    104\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    105\u001b[0m                 \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscorer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\family\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\u001b[0m in \u001b[0;36m_score\u001b[1;34m(self, method_caller, estimator, X, y_true, sample_weight)\u001b[0m\n\u001b[0;32m    256\u001b[0m         \"\"\"\n\u001b[0;32m    257\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 258\u001b[1;33m         \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmethod_caller\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"predict\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    259\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    260\u001b[0m             return self._sign * self._score_func(\n",
      "\u001b[1;32mc:\\users\\family\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\u001b[0m in \u001b[0;36m_cached_call\u001b[1;34m(cache, estimator, method, *args, **kwargs)\u001b[0m\n\u001b[0;32m     71\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mcache\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m         \u001b[0mcache\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\family\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\utils\\metaestimators.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    112\u001b[0m             \u001b[1;31m# lambda, but not partial, allows help() to work with update_wrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 113\u001b[1;33m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# noqa\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    114\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\family\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X, **predict_params)\u001b[0m\n\u001b[0;32m    467\u001b[0m         \u001b[0mXt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    468\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtransform\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwith_final\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 469\u001b[1;33m             \u001b[0mXt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    470\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mpredict_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    471\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\family\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py\u001b[0m in \u001b[0;36mtransform\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    751\u001b[0m             \u001b[0m_transform_one\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    752\u001b[0m             \u001b[0mfitted\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 753\u001b[1;33m             \u001b[0mcolumn_as_strings\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfit_dataframe_and_transform_dataframe\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    754\u001b[0m         )\n\u001b[0;32m    755\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_output\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\family\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py\u001b[0m in \u001b[0;36m_fit_transform\u001b[1;34m(self, X, y, func, fitted, column_as_strings)\u001b[0m\n\u001b[0;32m    613\u001b[0m                     \u001b[0mmessage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_log_message\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtransformers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    614\u001b[0m                 )\n\u001b[1;32m--> 615\u001b[1;33m                 \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrans\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtransformers\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    616\u001b[0m             )\n\u001b[0;32m    617\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\family\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    919\u001b[0m             \u001b[1;31m# remaining jobs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    920\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 921\u001b[1;33m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    922\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    923\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\family\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    757\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    758\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 759\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    760\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    761\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\family\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    714\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    715\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 716\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    717\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    718\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\family\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    180\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    181\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 182\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    183\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\family\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    547\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    548\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 549\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    550\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    551\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\family\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    223\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 225\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    226\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\family\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    223\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 225\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    226\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\family\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\utils\\fixes.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    214\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    215\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 216\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    217\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    218\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\family\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36m_transform_one\u001b[1;34m(transformer, X, y, weight, **fit_params)\u001b[0m\n\u001b[0;32m    874\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    875\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_transform_one\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 876\u001b[1;33m     \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    877\u001b[0m     \u001b[1;31m# if we have a weight for this transformer, multiply output\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    878\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mweight\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-162-2b8eb115d5d1>\u001b[0m in \u001b[0;36mtransform\u001b[1;34m(self, raw_documents)\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mraw_documents\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTfidfVectorizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mraw_documents\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\family\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36mtransform\u001b[1;34m(self, raw_documents)\u001b[0m\n\u001b[0;32m   2099\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"The TF-IDF vectorizer is not fitted\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2100\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2101\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mraw_documents\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2102\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_tfidf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2103\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\family\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36mtransform\u001b[1;34m(self, raw_documents)\u001b[0m\n\u001b[0;32m   1377\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1378\u001b[0m         \u001b[1;31m# use the same matrix-building strategy as fit_transform\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1379\u001b[1;33m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_count_vocab\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mraw_documents\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfixed_vocab\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1380\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbinary\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1381\u001b[0m             \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfill\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\family\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36m_count_vocab\u001b[1;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[0;32m   1201\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mfeature\u001b[0m \u001b[1;32min\u001b[0m \u001b[0manalyze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1202\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1203\u001b[1;33m                     \u001b[0mfeature_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1204\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mfeature_idx\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfeature_counter\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1205\u001b[0m                         \u001b[0mfeature_counter\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfeature_idx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for clf_name, clf_params in clfs.items():\n",
    "    clf, params = clf_params\n",
    "    if clf_name in tree_based:\n",
    "        pipeline = Pipeline(steps=[(\"vectorizer\", column_trans), (clf_name, clf)])\n",
    "    else:\n",
    "        pipeline = Pipeline(steps=[(\"vectorizer\", column_trans), (\"scaler\", scaler), (clf_name, clf)])\n",
    "    grid_search = GridSearchCV(pipeline, param_grid=params,\n",
    "                           scoring={\"F1\": \"f1_macro\", \"Accuracy\": \"accuracy\"},\n",
    "                           refit=\"F1\", return_train_score=True, cv=skf, verbose=10) \n",
    "    grid_search.fit(X_train, y_train)\n",
    "    best_f1_val = round(grid_search.best_score_, 4)\n",
    "    best_params = grid_search.best_params_\n",
    "    print(f\"Best f1 on validation: {best_f1_val}\")\n",
    "    print(\"Best parameters:\", best_params, \"\\n\")\n",
    "    estimator = grid_search.best_estimator_\n",
    "    \n",
    "    y_pred_test = estimator.predict(X_test)\n",
    "    acc, f1 = quality(y_test, y_pred_test)\n",
    "    \n",
    "    for metric, value in {\"F1 macro (validation)\": best_f1_val,\n",
    "                          \"Best params\": best_params,\n",
    "                          \"Accuracy (test)\": round(acc, 4),\n",
    "                          \"F1 macro (test)\": round(f1, 4)}.items():\n",
    "        results[\"lexical\"][metric][clf_name] = value\n",
    "        \n",
    "    if clf_name in tree_based:\n",
    "        feature_names = visualize_feature_importances(estimator, 10, \"lexical_\" + clf_name)\n",
    "    elif clf_name in with_coefs:\n",
    "        visualize_coefs(estimator, 10, \"lexical_\" + clf_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline = y_test.value_counts(normalize=True).max()\n",
    "\n",
    "# for feature_set in (\"lexical features\", \"morphological and syntactic features\", \"all features\"):\n",
    "mini_df = pd.DataFrame(results[\"lexical\"])\n",
    "mini_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lexical': {'F1 macro (validation)': {'lr': 0.8521},\n",
       "  'Best params': {'lr': {'lr__penalty': 'l1', 'vectorizer__word__min_df': 7}},\n",
       "  'Accuracy (test)': {'lr': 0.8518},\n",
       "  'F1 macro (test)': {'lr': 0.8512}}}"
      ]
     },
     "execution_count": 338,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "lexical\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD5CAYAAAA3Os7hAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAAWv0lEQVR4nO3df3BW1Z3H8feXJBqECAihosEmKGBiCAFCQMECisOPlh8ZZIuNqIsFGRfQolZAZRFtB6VVR9BFdqQo1QDi8KPAVocFRgpYSSCr/BCMGCTItgEk/IwhcPaPhGwISZ4n8ITI4fOaycxz7z3Pud8kzIeTc+89jznnEBGRy1+9ui5ARERCQ4EuIuIJBbqIiCcU6CIinlCgi4h4QoEuIuKJgIFuZnPM7J9mtrWK42Zmr5tZjpl9bmYdQ1+miIgEEswIfS7Qt5rj/YDWpV+jgP+4+LJERKSmAga6c+4T4FA1TQYB77oSnwKNzaxFqAoUEZHghIegjxuBveW280r37a/Y0MxGUTKKp0GDBp1uvfXWEJxeROTKkZWVdcA5F13ZsVAEetCcc7OB2QApKSkuMzPzUp5eROSyZ2Z7qjoWirtc9gEty23HlO4TEZFLKBSBvgx4oPRul65AgXPuvOkWERGpXQGnXMwsA+gJNDOzPODfgQgA59wsYCXQH8gBTgD/WlvFiohI1QIGunPuvgDHHfBvIatIRELm1KlT5OXlUVhYWNelSA1FRkYSExNDRERE0O+5pBdFReTSysvLIyoqitjYWMysrsuRIDnnOHjwIHl5ecTFxQX9Pj36L+KxwsJCmjZtqjC/zJgZTZs2rfFfVgp0Ec8pzC9PF/J7U6CLiHhCc+giV5DYCStC2l/utJ8H1W7JkiWkpaWxY8cOLscnxPfv38/IkSNZvnw52dnZfPfdd/Tv37/G/Rw+fJj333+fRx99FID8/HyGDx/OX//615DUqRG6iNS6jIwMunfvTkZGRq2e5/Tp07XS7yuvvMLIkSMByM7OZuXKlRfUz+HDh3nzzTfLtqOjo2nRogXr168PSZ0KdBGpVceOHeNvf/sbb7/9NvPnzy/bf/r0aZ588kkSExNJSkpixowZAGzatIk77riD9u3bk5qaytGjR5k7dy5jxowpe+8vfvEL1q5dC0DDhg154oknaN++PRs3bmTq1Kl07tyZxMRERo0aRcmd1ZCTk0Pv3r1p3749HTt25Ouvv+aBBx5gyZIlZf2mp6ezdOnS876HDz/8kL59+1JUVMTkyZNZsGABycnJLFiwgOPHjzNixAhSU1Pp0KFD2fu3bdtGamoqycnJJCUl8dVXXzFhwgS+/vprkpOTeeqppwAYPHgw7733Xkh+1ppyEZFatXTpUvr27UubNm1o2rQpWVlZdOrUidmzZ5Obm0t2djbh4eEcOnSIoqIifvnLX7JgwQI6d+7MkSNHqF+/frX9Hz9+nC5duvDHP/4RgISEBCZPngzA8OHDWb58OQMGDCA9PZ0JEyaQlpZGYWEhZ86c4eGHH+bVV19l8ODBFBQUsGHDBt55551z+v/mm29o0qQJV199NQBTp04lMzOTmTNnAjBp0iTuuusu5syZw+HDh0lNTaV3797MmjWLxx57jPT0dIqKijh9+jTTpk1j69atZGdnl/WfkpLCs88+G5KftUboIlKrMjIyGDZsGADDhg0rm3ZZtWoVjzzyCOHhJePK6667jp07d9KiRQs6d+4MwLXXXlt2vCphYWEMGTKkbHvNmjV06dKFdu3asXr1arZt28bRo0fZt28faWlpQMlDO9dccw09evTgq6++Ij8/n4yMDIYMGXLe+fbv3090dKWLGwLw8ccfM23aNJKTk+nZsyeFhYV8++233H777fz+97/npZdeYs+ePVX+x9S8eXO+++67ar/HYGmELiK15tChQ6xevZovvvgCM+P06dOYGdOnT69RP+Hh4Zw5c6Zsu/z92ZGRkYSFhZXtf/TRR8nMzKRly5ZMmTIl4L3cDzzwAH/+85+ZP38+f/rTn847Xr9+/Wr7cM7x4Ycf0rZt23P2x8fH06VLF1asWEH//v156623aNWq1XnvLywsDPhXSLA0QheRWrNo0SKGDx/Onj17yM3NZe/evcTFxbFu3Truuece3nrrLYqLi4GS8G/bti379+9n06ZNABw9epTi4mJiY2PJzs7mzJkz7N27l88++6zS850N3mbNmnHs2DEWLVoEQFRUFDExMWXz5T/88AMnTpwA4KGHHuK1114DSqZrKmrTpg25ubll21FRURw9erRsu0+fPsyYMaNsrn7Lli0A7N69m1atWjFu3DgGDRrE559/ft57AXbt2kViYmLQP9PqaIQucgUJ9jbDUMnIyODpp58+Z9+QIUPIyMhgxowZ7Nq1i6SkJCIiIhg5ciRjxoxhwYIFjB07lpMnT1K/fn1WrVpFt27diIuLIyEhgfj4eDp2rPyjixs3bszIkSNJTEzk+uuvL5u6AZg3bx6PPPIIkydPJiIigg8++IBWrVrxk5/8hPj4eAYPHlxpnw0aNODmm28mJyeHW265hV69epVNsUycOJHnnnuOxx9/nKSkJM6cOUNcXBzLly9n4cKFzJs3j4iICK6//nomTZrEddddR7du3UhMTKRfv35Mnz6dNWvW8POfh+b3Ymf/V7nU9AEXIrVvx44dxMfH13UZP2onTpygXbt2bN68mUaNGlXaZvHixWRlZfHiiy+G/Pw/+9nPWLp0KU2aNDnvWGW/PzPLcs6lVNaXplxE5Iq1atUq4uPjGTt2bJVhDpCWlkZsbGzIz5+fn8/48eMrDfMLoSkXEbli9e7dmz17qvxEt3P8+te/Dvn5o6Ojq5zquRAaoYuIeEKBLiLiCQW6iIgnFOgiIp7QRVGRK8mUqu/kuLD+CkLbn1wUjdBFpFaFhYWRnJxc9pWbm8vBgwfp1asXDRs2PGcVxR+z1157jXfffReAuXPnXvD6K2vXrmXDhg1l2zNnzmTOnDkhqVEjdBGpVfXr1z9ndUEoWSHxhRdeYOvWrWzdurVuCgOKi4sDLv51tt2cOXPYvHkzUBLoiYmJ3HDDDTU+59q1a2nYsCF33HEHACNGjKBbt26MGDGixn1VpBG6iFxyDRo0oHv37kRGRlbbLjY2lokTJ5KcnExKSgqbN2+mT58+3HzzzcyaNQsoWW/97rvvpmPHjrRr1+6c9czfffddkpKSaN++PcOHDwdK1m4ZPXo0Xbp04be//S3Z2dl07dqVpKQk0tLS+P7778+rY/Xq1XTs2JHw8HAWLVpEZmYm6enpJCcnc/LkSbKysujRowedOnWiT58+7N+/H4DXX3+dhIQEkpKSGDZsGLm5ucyaNYtXX32V5ORk1q1bxzXXXENsbGyV69PUhEboIlKrTp48SXJyMgBxcXEsXry4Ru+/6aabyM7O5je/+Q0PPfQQ69evp7CwkMTEREaPHk1kZCSLFy/m2muv5cCBA3Tt2pWBAweyfft2XnzxRTZs2ECzZs04dOhQWZ95eXls2LCBsLCwsg/X6NGjB5MnT+b5558vW6zrrPXr19OpUycA7r33XmbOnMkf/vAHUlJSOHXqFGPHjmXp0qVER0ezYMECnnnmGebMmcO0adP45ptvuPrqqzl8+DCNGzdm9OjRNGzYkCeffLKs/5SUFNatW0dqauqF/ZBLKdBFpFZVNuVSEwMHDgSgXbt2HDt2jKioKKKiospCskGDBkyaNIlPPvmEevXqsW/fPv7xj3+wevVqhg4dSrNmzYCS9dbPGjp0KGFhYRQUFHD48GF69OgBwIMPPsjQoUPPq2H//v1Vromzc+dOtm7dyj333AOUfBJTixYtAEhKSiI9PZ3BgwdX+0Ro8+bN+fLLL2v+w6lAgS4iP2pnPymoXr16Za/PbhcXF/Pee++Rn59PVlYWERERxMbGBlwDvUGDBjWqobo10Z1z3HbbbWzcuPG8YytWrOCTTz7hL3/5C7/73e/44osvKu0jVGuiK9BFriQe3mZYUFBA8+bNiYiIYM2aNWVrs9x1112kpaUxfvx4mjZtyqFDh84ZpQM0atSIJk2asG7dOu68807mzZtXNlovLz4+npycnLLt8uuat23blvz8fDZu3Mjtt9/OqVOn2LVrF/Hx8ezdu5devXrRvXt35s+fX/YXxpEjR87pf9euXXTr1u2ifxYKdE/ETlhR1yV4IzfyV3VdQuj0WQjfVT9arSuxsbEcOXKEoqIilixZwscff1zpB0wEkp6ezoABA2jXrh0pKSnceuutANx2220888wz9OjRg7CwMDp06MDcuXPPe/8777zD6NGjOXHiBK1atar0U4v69etXdlEV/v/Cav369dm4cSOLFi1i3LhxFBQUUFxczOOPP06bNm24//77KSgowDnHuHHjaNy4MQMGDODee+9l6dKlzJgxgzvvvJP169czZcqUGn/vFWk9dE8o0EPHp0Df0Wch8T9tXrdF3NChbs8fImlpabz88su0bt06pP1u2bKFV155hXnz5p13TOuhi4jUgmnTppXdjhhKBw4c4IUXXghJX5pyEfGawzmHmdV1IZe9tm3bnvdB0KFw9u6Yii5k9kQjdBGPRRbs5uDx4gsKB6k7zjkOHjwY8MGrijRCF/FYzOaXyONp8hu1AupolF6wo27Oe5mLjIwkJiamRu9RoIt4LKLoMHGfTqzbIjy8VfLHSlMuIiKeCCrQzayvme00sxwzm1DJ8ZvMbI2ZbTGzz82sf+hLFRGR6gQMdDMLA94A+gEJwH1mVvHu/2eBhc65DsAw4M1QFyoiItULZoSeCuQ453Y754qA+cCgCm0ccG3p60bAha38LiIiFyyYQL8R2FtuO690X3lTgPvNLA9YCYytrCMzG2VmmWaWmZ+ffwHliohIVUJ1UfQ+YK5zLgboD8wzs/P6ds7Nds6lOOdSoqOjQ3RqERGB4AJ9H9Cy3HZM6b7yHgYWAjjnNgKRQLNQFCgiIsEJJtA3Aa3NLM7MrqLkoueyCm2+Be4GMLN4SgJdcyoiIpdQwEB3zhUDY4CPgB2U3M2yzcymmtnA0mZPACPN7H+ADOAhp2eNRUQuqaCeFHXOraTkYmf5fZPLvd4OXPzq7CIicsH0pKiIiCcU6CIinlCgi4h4QoEuIuIJBbqIiCcU6CIinlCgi4h4QoEuIuIJBbqIiCcU6CIinlCgi4h4QoEuIuIJBbqIiCcU6CIinlCgi4h4QoEuIuIJBbqIiCcU6CIinlCgi4h4QoEuIuIJBbqIiCcU6CIinlCgi4h4QoEuIuIJBbqIiCcU6CIinlCgi4h4QoEuIuIJBbqIiCcU6CIinlCgi4h4QoEuIuIJBbqIiCcU6CIinggq0M2sr5ntNLMcM5tQRZt/MbPtZrbNzN4PbZkiIhJIeKAGZhYGvAHcA+QBm8xsmXNue7k2rYGJQDfn3Pdm1ry2ChYRkcoFM0JPBXKcc7udc0XAfGBQhTYjgTecc98DOOf+GdoyRUQkkGAC/UZgb7ntvNJ95bUB2pjZejP71Mz6VtaRmY0ys0wzy8zPz7+wikVEpFKhuigaDrQGegL3Af9pZo0rNnLOzXbOpTjnUqKjo0N0ahERgeACfR/Qstx2TOm+8vKAZc65U865b4BdlAS8iIhcIsEE+iagtZnFmdlVwDBgWYU2SygZnWNmzSiZgtkdujJFRCSQgIHunCsGxgAfATuAhc65bWY21cwGljb7CDhoZtuBNcBTzrmDtVW0iIicL+BtiwDOuZXAygr7Jpd77YDxpV8iIlIH9KSoiIgnFOgiIp5QoIuIeEKBLiLiCQW6iIgnFOgiIp5QoIuIeEKBLiLiCQW6iIgnFOgiIp5QoIuIeEKBLiLiCQW6iIgnFOgiIp5QoIuIeEKBLiLiCQW6iIgnFOgiIp5QoIuIeEKBLiLiCQW6iIgnFOgiIp5QoIuIeEKBLiLiCQW6iIgnFOgiIp5QoIuIeEKBLiLiCQW6iIgnFOgiIp5QoIuIeEKBLiLiCQW6iIgnFOgiIp5QoIuIeCKoQDezvma208xyzGxCNe2GmJkzs5TQlSgiIsEIGOhmFga8AfQDEoD7zCyhknZRwGPA30NdpIiIBBbMCD0VyHHO7XbOFQHzgUGVtHsBeAkoDGF9IiISpGAC/UZgb7ntvNJ9ZcysI9DSObeiuo7MbJSZZZpZZn5+fo2LFRGRql30RVEzqwe8AjwRqK1zbrZzLsU5lxIdHX2xpxYRkXKCCfR9QMty2zGl+86KAhKBtWaWC3QFlunCqIjIpRVMoG8CWptZnJldBQwDlp096JwrcM41c87FOudigU+Bgc65zFqpWEREKhUw0J1zxcAY4CNgB7DQObfNzKaa2cDaLlBERIITHkwj59xKYGWFfZOraNvz4ssSEZGa0pOiIiKeUKCLiHhCgS4i4gkFuoiIJxToIiKeUKCLiHhCgS4i4omg7kOvDTt37qRnz551dXrv/O/ug3Vdgjd61jte1yX4ZW3Puq7giqERuoiIJ+pshN62bVvWrl1bV6f3TuyEalculhpYG/mrui7BL1PW1nUFXjGzKo9phC4i4gkFuoiIJxToIiKeUKCLiHhCgS4i4gkFuoiIJxToIiKeUKCLiHhCgS4i4gkFuoiIJxToIiKeUKCLiHhCgS4i4gkFuoiIJxToIiKeUKCLiHhCgS4i4gkFuoiIJxToIiKeUKCLiHhCgS4i4gkFuoiIJxToIiKeUKCLiHgiqEA3s75mttPMcsxsQiXHx5vZdjP73Mz+28x+GvpSRUSkOgED3czCgDeAfkACcJ+ZJVRotgVIcc4lAYuAl0NdqIiIVC+YEXoqkOOc2+2cKwLmA4PKN3DOrXHOnSjd/BSICW2ZIiISSDCBfiOwt9x2Xum+qjwM/FdlB8xslJllmllmfn5+8FWKiEhAIb0oamb3AynA9MqOO+dmO+dSnHMp0dHRoTy1iMgVLzyINvuAluW2Y0r3ncPMegPPAD2ccz+EpjwREQlWMCP0TUBrM4szs6uAYcCy8g3MrAPwFjDQOffP0JcpIiKBBAx051wxMAb4CNgBLHTObTOzqWY2sLTZdKAh8IGZZZvZsiq6ExGRWhLMlAvOuZXAygr7Jpd73TvEdYmISA3pSVEREU8o0EVEPKFAFxHxhAJdRMQTCnQREU8o0EVEPKFAFxHxhAJdRMQTCnQREU8o0EVEPKFAFxHxhAJdRMQTCnQREU8o0EVEPKFAFxHxhAJdRMQTCnQREU8o0EVEPKFAFxHxhAJdRMQTCnQREU8o0EVEPKFAFxHxhAJdRMQTCnQREU8o0EVEPKFAFxHxhAJdRMQTCnQREU8o0EVEPKFAFxHxhAJdRMQTCnQREU8o0EVEPKFAFxHxRFCBbmZ9zWynmeWY2YRKjl9tZgtKj//dzGJDXqmIiFQrYKCbWRjwBtAPSADuM7OECs0eBr53zt0CvAq8FOpCRUSkesGM0FOBHOfcbudcETAfGFShzSDgndLXi4C7zcxCV6aIiAQSHkSbG4G95bbzgC5VtXHOFZtZAdAUOFC+kZmNAkaVbh4zs50XUrRIbTJoRoV/u3IRntfYLsR+WtWBYAI9ZJxzs4HZl/KcIjVlZpnOuZS6rkOkpoKZctkHtCy3HVO6r9I2ZhYONAIOhqJAEREJTjCBvglobWZxZnYVMAxYVqHNMuDB0tf3Aqudcy50ZYqISCABp1xK58THAB8BYcAc59w2M5sKZDrnlgFvA/PMLAc4REnoi1yuNC0olyXTQFpExA96UlRExBMKdBERTyjQRUQ8oUAXEfGEAl2ueGYWZmZf1nUdIhdLgS5XPOfcaWCnmd1U17WIXIxL+ui/yI9YE2CbmX0GHD+70zk3sO5KEqkZBbpIiefqugCRi6UHi0REPKERulzRzOwoUNmoxgDnnLv2EpckcsE0QhcR8YTuchER8YQCXUTEEwp0ERFPKNBFRDzxfy1xYwI5oTu8AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best result:\n",
      "Accuracy (test): 0.8518\n",
      "F1 macro (test): 0.8512\n"
     ]
    }
   ],
   "source": [
    "baseline = y_test.value_counts(normalize=True).max()\n",
    "\n",
    "# for feature_set in (\"lexical features\", \"morphological and syntactic features\", \"all features\"):\n",
    "for feature_set in (\"lexical\",):\n",
    "    mini_df = pd.DataFrame(results[feature_set])\n",
    "    mini_df.to_csv(f\"{feature_set}-results.csv\")\n",
    "    print(f\"\\n{feature_set}\")\n",
    "    mini_df[['Accuracy (test)', 'F1 macro (test)']].plot.bar()\n",
    "    plt.axhline(y=baseline, color=\"k\")\n",
    "    plt.ylim(0, 1)\n",
    "    plt.savefig(f\"{feature_set}-results.png\", bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"Best result:\")\n",
    "    \n",
    "    max_value = 0\n",
    "    best_clf = \"\"\n",
    "    for clf, value in results[feature_set][\"F1 macro (test)\"].items():\n",
    "        if value > max_value:\n",
    "            best_clf = clf\n",
    "    \n",
    "    for metric in (\"Accuracy (test)\", \"F1 macro (test)\"):\n",
    "        print(f\"{metric}: {results[feature_set][metric][clf]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
